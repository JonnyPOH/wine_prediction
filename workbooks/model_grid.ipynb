{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 998 entries, 0 to 997\n",
      "Data columns (total 6 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   country_encoded    998 non-null    int64  \n",
      " 1   points_scaled      998 non-null    float64\n",
      " 2   description_clean  998 non-null    object \n",
      " 3   variety_encoded    998 non-null    int64  \n",
      " 4   length_scaled      998 non-null    float64\n",
      " 5   price_scaled       998 non-null    float64\n",
      "dtypes: float64(3), int64(2), object(1)\n",
      "memory usage: 54.6+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load the dataset\n",
    "os.chdir(\"..\")\n",
    "data_path = 'datasets'\n",
    "df = pd.read_csv(os.path.join(data_path, 'wine_quality_transformed.csv'), index_col=0)\n",
    "\n",
    "# Display basic information about the dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_encoded</th>\n",
       "      <th>points_scaled</th>\n",
       "      <th>description_clean</th>\n",
       "      <th>variety_encoded</th>\n",
       "      <th>length_scaled</th>\n",
       "      <th>price_scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.354598</td>\n",
       "      <td>good dry creek zin robust dry spicy really get...</td>\n",
       "      <td>104</td>\n",
       "      <td>0.509537</td>\n",
       "      <td>-0.136111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.131082</td>\n",
       "      <td>herbaceous character make seem rather thin sof...</td>\n",
       "      <td>8</td>\n",
       "      <td>-1.219625</td>\n",
       "      <td>-0.493754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-1.131082</td>\n",
       "      <td>little simple easy wealth raspberry strawberry...</td>\n",
       "      <td>77</td>\n",
       "      <td>-1.219625</td>\n",
       "      <td>-0.575456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.057462</td>\n",
       "      <td>dry farmed vineyard treated wild yeast minimal...</td>\n",
       "      <td>61</td>\n",
       "      <td>0.077246</td>\n",
       "      <td>0.542865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0.948870</td>\n",
       "      <td>site near annapolis show preponderance dark gr...</td>\n",
       "      <td>66</td>\n",
       "      <td>-0.499141</td>\n",
       "      <td>1.345938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   country_encoded  points_scaled  \\\n",
       "0                3       0.354598   \n",
       "1                0      -1.131082   \n",
       "2                3      -1.131082   \n",
       "3                3       0.057462   \n",
       "4                3       0.948870   \n",
       "\n",
       "                                   description_clean  variety_encoded  \\\n",
       "0  good dry creek zin robust dry spicy really get...              104   \n",
       "1  herbaceous character make seem rather thin sof...                8   \n",
       "2  little simple easy wealth raspberry strawberry...               77   \n",
       "3  dry farmed vineyard treated wild yeast minimal...               61   \n",
       "4  site near annapolis show preponderance dark gr...               66   \n",
       "\n",
       "   length_scaled  price_scaled  \n",
       "0       0.509537     -0.136111  \n",
       "1      -1.219625     -0.493754  \n",
       "2      -1.219625     -0.575456  \n",
       "3       0.077246      0.542865  \n",
       "4      -0.499141      1.345938  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 224 candidates, totalling 1120 fits\n",
      "Best Model: Pipeline(steps=[('preprocessor',\n",
      "                 ColumnTransformer(transformers=[('tfidf', TfidfVectorizer(),\n",
      "                                                  'description_clean')])),\n",
      "                ('clf',\n",
      "                 SVC(C=10, degree=2, kernel='linear', probability=True))])\n",
      "Best Parameters: {'clf': SVC(kernel='linear', probability=True), 'clf__C': 10, 'clf__degree': 2, 'clf__gamma': 'scale', 'clf__kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define numeric and text features\n",
    "text_feature = \"description_clean\"\n",
    "numeric_features = [\"points_scaled\", \"variety_encoded\", \"length_scaled\", \"price_scaled\"]\n",
    "\n",
    "# Define column transformer (TF-IDF for text, scaling for numeric features)\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"tfidf\", TfidfVectorizer(), text_feature)  # Apply TF-IDF to text\n",
    "    # (\"num\", StandardScaler(), numeric_features)  # Scale numeric features\n",
    "])\n",
    "\n",
    "# Define different models to try\n",
    "models = {\n",
    "    \"RandomForest\": RandomForestClassifier(random_state=42),\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=500),\n",
    "    \"SVM\": SVC(kernel=\"linear\", probability=True),\n",
    "    \"NaiveBayes\": MultinomialNB()\n",
    "}\n",
    "\n",
    "# Create a pipeline with preprocessing + placeholder classifier\n",
    "pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"clf\", RandomForestClassifier(random_state=42))  # Placeholder classifier\n",
    "])\n",
    "\n",
    "# Define hyperparameter grid with multiple models\n",
    "param_grid = [\n",
    "    {\n",
    "        \"clf\": [RandomForestClassifier(random_state=42)],\n",
    "        \"clf__n_estimators\": [100, 200],\n",
    "        \"clf__max_depth\": [None, 10]\n",
    "    },\n",
    "    {\n",
    "        \"clf\": [LogisticRegression(max_iter=500)],\n",
    "        \"clf__C\": [0.01, 0.1, 1, 10],  # Regularization strength\n",
    "    },\n",
    "    {\n",
    "        \"clf\": [SVC(kernel=\"linear\", probability=True)],\n",
    "        \"clf__C\": [0.01, 0.1, 1, 10],\n",
    "        \"clf__kernel\": ['linear', 'rbf', 'poly'],\n",
    "        \"clf__gamma\": ['scale', 'auto', 0.01, 0,1, 1],\n",
    "        \"clf__degree\": [2, 3, 4],\n",
    "    }\n",
    "    # {\n",
    "    #     \"clf\": [MultinomialNB()],\n",
    "    #     \"clf__alpha\": [0.1, 0.5, 1.0]  # Smoothing parameter\n",
    "    # }\n",
    "]\n",
    "\n",
    "# Ensure data is clean\n",
    "df = df.dropna(subset=[\"description_clean\", \"country_encoded\"])\n",
    "\n",
    "# Define X and y correctly\n",
    "X = df[[text_feature] + numeric_features]\n",
    "y = df[\"country_encoded\"]\n",
    "\n",
    "# Perform Grid Search with multiple models\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring=\"accuracy\", verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Print best parameters and model\n",
    "print(\"Best Model:\", grid_search.best_estimator_)\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wine_model.pkl']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "joblib.dump(best_model, \"wine_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_clean</th>\n",
       "      <th>points_scaled</th>\n",
       "      <th>variety_encoded</th>\n",
       "      <th>length_scaled</th>\n",
       "      <th>price_scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>good dry creek zin robust dry spicy really get...</td>\n",
       "      <td>0.354598</td>\n",
       "      <td>104</td>\n",
       "      <td>0.509537</td>\n",
       "      <td>-0.136111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>herbaceous character make seem rather thin sof...</td>\n",
       "      <td>-1.131082</td>\n",
       "      <td>8</td>\n",
       "      <td>-1.219625</td>\n",
       "      <td>-0.493754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>little simple easy wealth raspberry strawberry...</td>\n",
       "      <td>-1.131082</td>\n",
       "      <td>77</td>\n",
       "      <td>-1.219625</td>\n",
       "      <td>-0.575456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dry farmed vineyard treated wild yeast minimal...</td>\n",
       "      <td>0.057462</td>\n",
       "      <td>61</td>\n",
       "      <td>0.077246</td>\n",
       "      <td>0.542865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>site near annapolis show preponderance dark gr...</td>\n",
       "      <td>0.948870</td>\n",
       "      <td>66</td>\n",
       "      <td>-0.499141</td>\n",
       "      <td>1.345938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>made using selection fruit sourced bank serein...</td>\n",
       "      <td>-0.239674</td>\n",
       "      <td>15</td>\n",
       "      <td>-0.931431</td>\n",
       "      <td>0.408828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>quite green also raisiny really compute seeing...</td>\n",
       "      <td>-1.725354</td>\n",
       "      <td>72</td>\n",
       "      <td>0.365440</td>\n",
       "      <td>-0.661349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>mountain fruit key understanding cab meant uni...</td>\n",
       "      <td>1.543143</td>\n",
       "      <td>12</td>\n",
       "      <td>1.518215</td>\n",
       "      <td>1.867083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>hat zonin family among first offer viognier so...</td>\n",
       "      <td>0.057462</td>\n",
       "      <td>100</td>\n",
       "      <td>0.077246</td>\n",
       "      <td>-0.949123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>beautifully drinkable merlot softly tannic qui...</td>\n",
       "      <td>0.948870</td>\n",
       "      <td>51</td>\n",
       "      <td>-0.210947</td>\n",
       "      <td>-0.201788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>998 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     description_clean  points_scaled  \\\n",
       "0    good dry creek zin robust dry spicy really get...       0.354598   \n",
       "1    herbaceous character make seem rather thin sof...      -1.131082   \n",
       "2    little simple easy wealth raspberry strawberry...      -1.131082   \n",
       "3    dry farmed vineyard treated wild yeast minimal...       0.057462   \n",
       "4    site near annapolis show preponderance dark gr...       0.948870   \n",
       "..                                                 ...            ...   \n",
       "993  made using selection fruit sourced bank serein...      -0.239674   \n",
       "994  quite green also raisiny really compute seeing...      -1.725354   \n",
       "995  mountain fruit key understanding cab meant uni...       1.543143   \n",
       "996  hat zonin family among first offer viognier so...       0.057462   \n",
       "997  beautifully drinkable merlot softly tannic qui...       0.948870   \n",
       "\n",
       "     variety_encoded  length_scaled  price_scaled  \n",
       "0                104       0.509537     -0.136111  \n",
       "1                  8      -1.219625     -0.493754  \n",
       "2                 77      -1.219625     -0.575456  \n",
       "3                 61       0.077246      0.542865  \n",
       "4                 66      -0.499141      1.345938  \n",
       "..               ...            ...           ...  \n",
       "993               15      -0.931431      0.408828  \n",
       "994               72       0.365440     -0.661349  \n",
       "995               12       1.518215      1.867083  \n",
       "996              100       0.077246     -0.949123  \n",
       "997               51      -0.210947     -0.201788  \n",
       "\n",
       "[998 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "description_clean     object\n",
      "points_scaled        float64\n",
      "variety_encoded        int64\n",
      "text_length            int64\n",
      "price_log            float64\n",
      "price_scaled         float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'cv_results_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Convert Grid Search results into a DataFrame\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m results_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv_results_\u001b[49m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Select relevant columns for evaluation\u001b[39;00m\n\u001b[1;32m      5\u001b[0m results_df \u001b[38;5;241m=\u001b[39m results_df[\n\u001b[1;32m      6\u001b[0m     [\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparam_clf\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# Model type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m     ]\n\u001b[1;32m     18\u001b[0m ]\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean_test_score\u001b[39m\u001b[38;5;124m\"\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'cv_results_'"
     ]
    }
   ],
   "source": [
    "# Convert Grid Search results into a DataFrame\n",
    "results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "\n",
    "# Select relevant columns for evaluation\n",
    "results_df = results_df[\n",
    "    [\n",
    "        \"param_clf\",  # Model type\n",
    "        \"param_clf__n_estimators\",  # RF: Number of estimators\n",
    "        \"param_clf__max_depth\",  # RF: Max depth\n",
    "        \"param_clf__C\",  # Logistic Regression / SVM regularization\n",
    "        # \"param_clf__alpha\",  # Naive Bayes smoothing\n",
    "        \"mean_test_score\",  # Mean accuracy score\n",
    "        \"std_test_score\",  # Standard deviation of accuracy score\n",
    "        \"param_clf__kernel\",\n",
    "        \"param_clf__gamma\",\n",
    "        \"param_clf__degree\"\n",
    "    ]\n",
    "].sort_values(by=\"mean_test_score\", ascending=False)\n",
    "\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.compose import ColumnTransformer\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# # Define numeric and text features\n",
    "# text_feature = \"description_clean\"\n",
    "# numeric_features = [\"points_scaled\", \"variety_encoded\",\"text_length\",\"price_log\",\"price_scaled\"]\n",
    "\n",
    "# # Define column transformer (TF-IDF for text, passthrough for numeric)\n",
    "# preprocessor = ColumnTransformer([\n",
    "#     (\"tfidf\", TfidfVectorizer(), text_feature),  # Apply TF-IDF to text\n",
    "#     (\"num\", \"passthrough\", numeric_features)  # Keep numeric features unchanged\n",
    "# ])\n",
    "\n",
    "# # Define pipeline with preprocessing + model\n",
    "# pipeline = Pipeline([\n",
    "#     (\"preprocessor\", preprocessor),\n",
    "#     (\"clf\", RandomForestClassifier(random_state=42))\n",
    "# ])\n",
    "\n",
    "# # Define hyperparameter grid\n",
    "# param_grid = {\n",
    "#     \"preprocessor__tfidf__max_features\": [500, 1000, 2000],  # TF-IDF vocabulary\n",
    "#     \"preprocessor__tfidf__ngram_range\": [(1,1), (1,2)],  # Unigrams vs. bigrams\n",
    "#     \"preprocessor__tfidf__min_df\": [1, 2],  # Min doc frequency\n",
    "#     \"preprocessor__tfidf__max_df\": [0.9, 1.0],  # Max doc frequency\n",
    "#     \"preprocessor__tfidf__stop_words\": [None, \"english\"],  # Stopword removal\n",
    "#     \"clf__n_estimators\": [100, 200],  # RandomForest trees\n",
    "#     \"clf__max_depth\": [None, 10],  # Max tree depth\n",
    "# }\n",
    "\n",
    "# # Ensure data is clean\n",
    "# df = df.dropna(subset=[\"description_clean\", \"country_encoded\"])\n",
    "\n",
    "# # Define X and y correctly\n",
    "# X = df[[text_feature] + numeric_features]  # Include both text & numeric features\n",
    "# y = df[\"country_encoded\"]\n",
    "\n",
    "# # Perform Grid Search with correct feature processing\n",
    "# grid_search = GridSearchCV(pipeline, param_grid, cv=3, scoring=\"accuracy\", verbose=1, n_jobs=-1)\n",
    "# grid_search.fit(X, y)\n",
    "\n",
    "# # Print best parameters\n",
    "# print(\"Best Parameters Found:\", grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(grid_search.cv_results_)\n",
    "best_three = results.sort_values(by='mean_test_score', ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP 3:\n",
      "170    0.849683\n",
      "203    0.849683\n",
      "173    0.849683\n",
      "Name: mean_test_score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(f\"TOP 3:\\n{best_three['mean_test_score']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 45 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n45 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/jonnyoh/.pyenv/versions/3.12.4/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/jonnyoh/.pyenv/versions/3.12.4/lib/python3.12/site-packages/sklearn/base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jonnyoh/.pyenv/versions/3.12.4/lib/python3.12/site-packages/sklearn/pipeline.py\", line 654, in fit\n    Xt = self._fit(X, y, routed_params, raw_params=params)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jonnyoh/.pyenv/versions/3.12.4/lib/python3.12/site-packages/sklearn/pipeline.py\", line 588, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jonnyoh/.pyenv/versions/3.12.4/lib/python3.12/site-packages/joblib/memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jonnyoh/.pyenv/versions/3.12.4/lib/python3.12/site-packages/sklearn/pipeline.py\", line 1551, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jonnyoh/.pyenv/versions/3.12.4/lib/python3.12/site-packages/sklearn/utils/_set_output.py\", line 319, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jonnyoh/.pyenv/versions/3.12.4/lib/python3.12/site-packages/sklearn/base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jonnyoh/.pyenv/versions/3.12.4/lib/python3.12/site-packages/sklearn/compose/_column_transformer.py\", line 990, in fit_transform\n    self._validate_transformers()\n  File \"/home/jonnyoh/.pyenv/versions/3.12.4/lib/python3.12/site-packages/sklearn/compose/_column_transformer.py\", line 517, in _validate_transformers\n    names, transformers, _ = zip(*self.transformers)\n    ^^^^^^^^^^^^^^^^^^^^^^\nValueError: not enough values to unpack (expected 3, got 2)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 68\u001b[0m\n\u001b[1;32m     65\u001b[0m y \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcountry_encoded\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Fit grid search\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# Print best parameters and model\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Model:\u001b[39m\u001b[38;5;124m\"\u001b[39m, grid_search\u001b[38;5;241m.\u001b[39mbest_estimator_)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.4/lib/python3.12/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.4/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1024\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1018\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1019\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1020\u001b[0m     )\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1024\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1027\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1028\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.4/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1571\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1570\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1571\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.4/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1001\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    994\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[1;32m    995\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    996\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    997\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    998\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[1;32m    999\u001b[0m     )\n\u001b[0;32m-> 1001\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1003\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[1;32m   1004\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[1;32m   1005\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[1;32m   1006\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[1;32m   1007\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.4/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:517\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[1;32m    511\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    512\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    515\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    516\u001b[0m     )\n\u001b[0;32m--> 517\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    519\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    520\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    521\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    522\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    526\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    527\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: \nAll the 45 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n45 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/jonnyoh/.pyenv/versions/3.12.4/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/jonnyoh/.pyenv/versions/3.12.4/lib/python3.12/site-packages/sklearn/base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jonnyoh/.pyenv/versions/3.12.4/lib/python3.12/site-packages/sklearn/pipeline.py\", line 654, in fit\n    Xt = self._fit(X, y, routed_params, raw_params=params)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jonnyoh/.pyenv/versions/3.12.4/lib/python3.12/site-packages/sklearn/pipeline.py\", line 588, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jonnyoh/.pyenv/versions/3.12.4/lib/python3.12/site-packages/joblib/memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jonnyoh/.pyenv/versions/3.12.4/lib/python3.12/site-packages/sklearn/pipeline.py\", line 1551, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jonnyoh/.pyenv/versions/3.12.4/lib/python3.12/site-packages/sklearn/utils/_set_output.py\", line 319, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jonnyoh/.pyenv/versions/3.12.4/lib/python3.12/site-packages/sklearn/base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jonnyoh/.pyenv/versions/3.12.4/lib/python3.12/site-packages/sklearn/compose/_column_transformer.py\", line 990, in fit_transform\n    self._validate_transformers()\n  File \"/home/jonnyoh/.pyenv/versions/3.12.4/lib/python3.12/site-packages/sklearn/compose/_column_transformer.py\", line 517, in _validate_transformers\n    names, transformers, _ = zip(*self.transformers)\n    ^^^^^^^^^^^^^^^^^^^^^^\nValueError: not enough values to unpack (expected 3, got 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "\n",
    "# Define numeric and text features\n",
    "text_feature = \"description_clean\"\n",
    "numeric_features = [\"points_scaled\", \"variety_encoded\", \"text_length\", \"price_log\", \"price_scaled\"]\n",
    "\n",
    "# Define column transformer (TF-IDF for text, passthrough for numeric)\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"tfidf\", TfidfVectorizer()),  # Apply TF-IDF to text\n",
    "    (\"num\", \"passthrough\", numeric_features)  # Keep numeric features unchanged\n",
    "])\n",
    "\n",
    "# Define different models to try\n",
    "models = {\n",
    "    \"RandomForest\": RandomForestClassifier(random_state=42),\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=500),\n",
    "    \"SVM\": SVC(kernel=\"linear\", probability=True),\n",
    "    \"NaiveBayes\": MultinomialNB()\n",
    "}\n",
    "\n",
    "# Create a pipeline with a placeholder classifier (will be replaced)\n",
    "pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"clf\", RandomForestClassifier(random_state=42))  # Placeholder, will be changed in GridSearchCV\n",
    "])\n",
    "\n",
    "# Define hyperparameter grid for different models\n",
    "param_grid = [\n",
    "    {\n",
    "        \"clf\": [RandomForestClassifier(random_state=42)],\n",
    "        \"clf__n_estimators\": [100, 200],\n",
    "        \"clf__max_depth\": [None, 10]\n",
    "    },\n",
    "    {\n",
    "        \"clf\": [LogisticRegression(max_iter=500)],\n",
    "        \"clf__C\": [0.01, 0.1, 1, 10],  # Regularization strength\n",
    "    },\n",
    "    {\n",
    "        \"clf\": [SVC(kernel=\"linear\", probability=True)],\n",
    "        \"clf__C\": [0.01, 0.1, 1, 10]\n",
    "    },\n",
    "    {\n",
    "        \"clf\": [MultinomialNB()],\n",
    "        \"clf__alpha\": [0.1, 0.5, 1.0]  # Smoothing parameter\n",
    "    }\n",
    "]\n",
    "\n",
    "# Perform Grid Search with multiple models\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=3, scoring=\"accuracy\", verbose=1, n_jobs=-1)\n",
    "\n",
    "# Ensure data is clean\n",
    "df = df.dropna(subset=[\"description_clean\", \"country_encoded\"])\n",
    "\n",
    "# Define X and y correctly\n",
    "X = df[[text_feature] + numeric_features]\n",
    "y = df[\"country_encoded\"]\n",
    "\n",
    "# Fit grid search\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Print best parameters and model\n",
    "print(\"Best Model:\", grid_search.best_estimator_)\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
